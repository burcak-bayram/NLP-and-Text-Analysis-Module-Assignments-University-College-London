{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burcak-bayram/NLP-and-Text-Analysis-Module-Assignments-University-College-London/blob/main/23223014_INST0073_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c540dbf7",
      "metadata": {
        "id": "c540dbf7"
      },
      "source": [
        "# Comparing and Contrasting Popular NLP Frameworks and Libraries: The Case Study of Lemmatisation and Part of Speech Tagging\n",
        "### 6 March 2024, University College London\n",
        "### Module: Natural Language Processing and Text Analysis (INST0073)\n",
        "### Module tutor: Andreas Vlachidis\n",
        "\n",
        "This is a task I have been assigned to process a large corpus of News articles. The following steps showcase how I will be implementing it:\n",
        "\n",
        "**-Retrieve specific sentences from the Brown Corpus via NLTK:** To extract sentences numbered 014 to 023 within the \"News\" category for analysis.\n",
        "\n",
        "**-Sentence Processing Using NLTK and spaCy:**\n",
        "   - NLTK for tokenization on the sentences followed by POS tagging and lemmatization.\n",
        "   - spaCy for processing sentences using its integrated pipeline.\n",
        "   \n",
        "**-Analysis of Lemmatizaiton and POS tagging results** to compare the outcomes of both frameworks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive on Colab\n",
        "This notebook file was created on Colab, and to save the generated results we need to have access to Google Drive. The following code will ensure that we can access Google Drive."
      ],
      "metadata": {
        "id": "p7QmO0DQjqln"
      },
      "id": "p7QmO0DQjqln"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O821HP_gjrSN",
        "outputId": "5368ca94-744d-43dd-f845-74ef9a4bfb2d"
      },
      "id": "O821HP_gjrSN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b887049f",
      "metadata": {
        "id": "b887049f"
      },
      "source": [
        "## Access the Brown Corpus\n",
        "Let's begin by importing necessary libraries, accessing and preparing the sentences from the Brown Corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f27a2c51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f27a2c51",
        "outputId": "29b2e2ef-dc30-42a4-f964-271c6f96cba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Import NLTK modules and download NLTK resources\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import brown\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#import spaCy modules\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "# Ensure NLTK required for processing:Brown corpus, tokenizers, POS taggers, Wordnet lemmatizer\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1390fc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1390fc5",
        "outputId": "2588778b-0666-40e3-fb6d-7b06823e32ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 14: `` This is one of the major items in the Fulton County general assistance program '' , the jury said , but the State Welfare Department `` has seen fit to distribute these funds through the welfare departments of all the counties in the state with the exception of Fulton County , which receives none of this money .\n",
            "Sentence 15: The jurors said they realize `` a proportionate distribution of these funds might disable this program in our less populous counties '' .\n",
            "Sentence 16: Nevertheless , `` we feel that in the future Fulton County should receive some portion of these available funds '' , the jurors said .\n",
            "Sentence 17: `` Failure to do this will continue to place a disproportionate burden '' on Fulton taxpayers .\n",
            "Sentence 18: The jury also commented on the Fulton ordinary's court which has been under fire for its practices in the appointment of appraisers , guardians and administrators and the awarding of fees and compensation .\n",
            "Sentence 19: Wards protected\n",
            "Sentence 20: The jury said it found the court `` has incorporated into its operating procedures the recommendations '' of two previous grand juries , the Atlanta Bar Association and an interim citizens committee .\n",
            "Sentence 21: `` These actions should serve to protect in fact and in effect the court's wards from undue costs and its appointed and elected servants from unmeritorious criticisms '' , the jury said .\n",
            "Sentence 22: Regarding Atlanta's new multi-million-dollar airport , the jury recommended `` that when the new management takes charge Jan. 1 the airport be operated in a manner that will eliminate political influences '' .\n",
            "Sentence 23: The jury did not elaborate , but it added that `` there should be periodic surveillance of the pricing practices of the concessionaires for the purpose of keeping the prices reasonable '' .\n"
          ]
        }
      ],
      "source": [
        "# Load the English model for spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Accessing sentences from the \"News\" category of the Brown Corpus directly\n",
        "news_sentences = brown.sents(categories='news')\n",
        "\n",
        "# Initialize an empty list to store selected sentences\n",
        "selected_sentences = []\n",
        "\n",
        "# Loop through the specific range based on the student ID, 23223014 (i.e., sentences 14 through 23)\n",
        "for i in range(14, 24):\n",
        "    # Join words in each sentence to form a string and add it to the list\n",
        "    selected_sentences.append(' '.join(news_sentences[i]))\n",
        "\n",
        "# Iterate over the selected sentences and print them with their corresponding index\n",
        "for i in range(14, 24):\n",
        "    print(f\"Sentence {i}: {selected_sentences[i-14]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd4049a3",
      "metadata": {
        "id": "dd4049a3"
      },
      "source": [
        "## NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca3b324",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ca3b324",
        "outputId": "dd42d60b-dd22-45b4-9880-656b4f815e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing with NLTK:\n",
            "Sentence 14 (Word, Lemma, POS): [('``', '``', '``'), ('This', 'This', 'DT'), ('is', 'is', 'VBZ'), ('one', 'one', 'CD'), ('of', 'of', 'IN'), ('the', 'the', 'DT'), ('major', 'major', 'JJ'), ('items', 'item', 'NNS'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('Fulton', 'Fulton', 'NNP'), ('County', 'County', 'NNP'), ('general', 'general', 'JJ'), ('assistance', 'assistance', 'NN'), ('program', 'program', 'NN'), ('``', '``', '``'), (',', ',', ','), ('the', 'the', 'DT'), ('jury', 'jury', 'NN'), ('said', 'said', 'VBD'), (',', ',', ','), ('but', 'but', 'CC'), ('the', 'the', 'DT'), ('State', 'State', 'NNP'), ('Welfare', 'Welfare', 'NNP'), ('Department', 'Department', 'NNP'), ('``', '``', '``'), ('has', 'ha', 'VBZ'), ('seen', 'seen', 'VBN'), ('fit', 'fit', 'NN'), ('to', 'to', 'TO'), ('distribute', 'distribute', 'VB'), ('these', 'these', 'DT'), ('funds', 'fund', 'NNS'), ('through', 'through', 'IN'), ('the', 'the', 'DT'), ('welfare', 'welfare', 'NN'), ('departments', 'department', 'NNS'), ('of', 'of', 'IN'), ('all', 'all', 'PDT'), ('the', 'the', 'DT'), ('counties', 'county', 'NNS'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('state', 'state', 'NN'), ('with', 'with', 'IN'), ('the', 'the', 'DT'), ('exception', 'exception', 'NN'), ('of', 'of', 'IN'), ('Fulton', 'Fulton', 'NNP'), ('County', 'County', 'NNP'), (',', ',', ','), ('which', 'which', 'WDT'), ('receives', 'receives', 'VBZ'), ('none', 'none', 'NN'), ('of', 'of', 'IN'), ('this', 'this', 'DT'), ('money', 'money', 'NN'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 15 (Word, Lemma, POS): [('The', 'The', 'DT'), ('jurors', 'juror', 'NNS'), ('said', 'said', 'VBD'), ('they', 'they', 'PRP'), ('realize', 'realize', 'VBP'), ('``', '``', '``'), ('a', 'a', 'DT'), ('proportionate', 'proportionate', 'JJ'), ('distribution', 'distribution', 'NN'), ('of', 'of', 'IN'), ('these', 'these', 'DT'), ('funds', 'fund', 'NNS'), ('might', 'might', 'MD'), ('disable', 'disable', 'VB'), ('this', 'this', 'DT'), ('program', 'program', 'NN'), ('in', 'in', 'IN'), ('our', 'our', 'PRP$'), ('less', 'le', 'CC'), ('populous', 'populous', 'JJ'), ('counties', 'county', 'NNS'), ('``', '``', '``'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 16 (Word, Lemma, POS): [('Nevertheless', 'Nevertheless', 'RB'), (',', ',', ','), ('``', '``', '``'), ('we', 'we', 'PRP'), ('feel', 'feel', 'VBP'), ('that', 'that', 'IN'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('future', 'future', 'JJ'), ('Fulton', 'Fulton', 'NNP'), ('County', 'County', 'NNP'), ('should', 'should', 'MD'), ('receive', 'receive', 'VB'), ('some', 'some', 'DT'), ('portion', 'portion', 'NN'), ('of', 'of', 'IN'), ('these', 'these', 'DT'), ('available', 'available', 'JJ'), ('funds', 'fund', 'NNS'), ('``', '``', '``'), (',', ',', ','), ('the', 'the', 'DT'), ('jurors', 'juror', 'NNS'), ('said', 'said', 'VBD'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 17 (Word, Lemma, POS): [('``', '``', '``'), ('Failure', 'Failure', 'NN'), ('to', 'to', 'TO'), ('do', 'do', 'VB'), ('this', 'this', 'DT'), ('will', 'will', 'MD'), ('continue', 'continue', 'VB'), ('to', 'to', 'TO'), ('place', 'place', 'VB'), ('a', 'a', 'DT'), ('disproportionate', 'disproportionate', 'NN'), ('burden', 'burden', 'NN'), ('``', '``', '``'), ('on', 'on', 'IN'), ('Fulton', 'Fulton', 'NNP'), ('taxpayers', 'taxpayer', 'NNS'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 18 (Word, Lemma, POS): [('The', 'The', 'DT'), ('jury', 'jury', 'NN'), ('also', 'also', 'RB'), ('commented', 'commented', 'VBN'), ('on', 'on', 'IN'), ('the', 'the', 'DT'), ('Fulton', 'Fulton', 'NNP'), ('ordinary', 'ordinary', 'NNP'), (\"'s\", \"'s\", 'POS'), ('court', 'court', 'NN'), ('which', 'which', 'WDT'), ('has', 'ha', 'VBZ'), ('been', 'been', 'VBN'), ('under', 'under', 'IN'), ('fire', 'fire', 'NN'), ('for', 'for', 'IN'), ('its', 'it', 'PRP$'), ('practices', 'practice', 'NNS'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('appointment', 'appointment', 'NN'), ('of', 'of', 'IN'), ('appraisers', 'appraiser', 'NNS'), (',', ',', ','), ('guardians', 'guardian', 'NNS'), ('and', 'and', 'CC'), ('administrators', 'administrator', 'NNS'), ('and', 'and', 'CC'), ('the', 'the', 'DT'), ('awarding', 'awarding', 'NN'), ('of', 'of', 'IN'), ('fees', 'fee', 'NNS'), ('and', 'and', 'CC'), ('compensation', 'compensation', 'NN'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 19 (Word, Lemma, POS): [('Wards', 'Wards', 'NNS'), ('protected', 'protected', 'VBD')]\n",
            "\n",
            "Sentence 20 (Word, Lemma, POS): [('The', 'The', 'DT'), ('jury', 'jury', 'NN'), ('said', 'said', 'VBD'), ('it', 'it', 'PRP'), ('found', 'found', 'VBD'), ('the', 'the', 'DT'), ('court', 'court', 'NN'), ('``', '``', '``'), ('has', 'ha', 'VBZ'), ('incorporated', 'incorporated', 'VBN'), ('into', 'into', 'IN'), ('its', 'it', 'PRP$'), ('operating', 'operating', 'NN'), ('procedures', 'procedure', 'VBZ'), ('the', 'the', 'DT'), ('recommendations', 'recommendation', 'NNS'), ('``', '``', '``'), ('of', 'of', 'IN'), ('two', 'two', 'CD'), ('previous', 'previous', 'JJ'), ('grand', 'grand', 'JJ'), ('juries', 'jury', 'NNS'), (',', ',', ','), ('the', 'the', 'DT'), ('Atlanta', 'Atlanta', 'NNP'), ('Bar', 'Bar', 'NNP'), ('Association', 'Association', 'NNP'), ('and', 'and', 'CC'), ('an', 'an', 'DT'), ('interim', 'interim', 'JJ'), ('citizens', 'citizen', 'NNS'), ('committee', 'committee', 'NN'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 21 (Word, Lemma, POS): [('``', '``', '``'), ('These', 'These', 'DT'), ('actions', 'action', 'NNS'), ('should', 'should', 'MD'), ('serve', 'serve', 'VB'), ('to', 'to', 'TO'), ('protect', 'protect', 'VB'), ('in', 'in', 'IN'), ('fact', 'fact', 'NN'), ('and', 'and', 'CC'), ('in', 'in', 'IN'), ('effect', 'effect', 'NN'), ('the', 'the', 'DT'), ('court', 'court', 'NN'), (\"'s\", \"'s\", 'POS'), ('wards', 'ward', 'NNS'), ('from', 'from', 'IN'), ('undue', 'undue', 'JJ'), ('costs', 'cost', 'NNS'), ('and', 'and', 'CC'), ('its', 'it', 'PRP$'), ('appointed', 'appointed', 'VBN'), ('and', 'and', 'CC'), ('elected', 'elected', 'VBN'), ('servants', 'servant', 'NNS'), ('from', 'from', 'IN'), ('unmeritorious', 'unmeritorious', 'JJ'), ('criticisms', 'criticism', 'NNS'), ('``', '``', '``'), (',', ',', ','), ('the', 'the', 'DT'), ('jury', 'jury', 'NN'), ('said', 'said', 'VBD'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 22 (Word, Lemma, POS): [('Regarding', 'Regarding', 'VBG'), ('Atlanta', 'Atlanta', 'NNP'), (\"'s\", \"'s\", 'POS'), ('new', 'new', 'JJ'), ('multi-million-dollar', 'multi-million-dollar', 'JJ'), ('airport', 'airport', 'NN'), (',', ',', ','), ('the', 'the', 'DT'), ('jury', 'jury', 'NN'), ('recommended', 'recommended', 'VBD'), ('``', '``', '``'), ('that', 'that', 'IN'), ('when', 'when', 'WRB'), ('the', 'the', 'DT'), ('new', 'new', 'JJ'), ('management', 'management', 'NN'), ('takes', 'take', 'VBZ'), ('charge', 'charge', 'NN'), ('Jan.', 'Jan.', 'NNP'), ('1', '1', 'CD'), ('the', 'the', 'DT'), ('airport', 'airport', 'NN'), ('be', 'be', 'VB'), ('operated', 'operated', 'VBN'), ('in', 'in', 'IN'), ('a', 'a', 'DT'), ('manner', 'manner', 'NN'), ('that', 'that', 'WDT'), ('will', 'will', 'MD'), ('eliminate', 'eliminate', 'VB'), ('political', 'political', 'JJ'), ('influences', 'influence', 'NNS'), ('``', '``', '``'), ('.', '.', '.')]\n",
            "\n",
            "Sentence 23 (Word, Lemma, POS): [('The', 'The', 'DT'), ('jury', 'jury', 'NN'), ('did', 'did', 'VBD'), ('not', 'not', 'RB'), ('elaborate', 'elaborate', 'JJ'), (',', ',', ','), ('but', 'but', 'CC'), ('it', 'it', 'PRP'), ('added', 'added', 'VBD'), ('that', 'that', 'IN'), ('``', '``', '``'), ('there', 'there', 'EX'), ('should', 'should', 'MD'), ('be', 'be', 'VB'), ('periodic', 'periodic', 'JJ'), ('surveillance', 'surveillance', 'NN'), ('of', 'of', 'IN'), ('the', 'the', 'DT'), ('pricing', 'pricing', 'NN'), ('practices', 'practice', 'NNS'), ('of', 'of', 'IN'), ('the', 'the', 'DT'), ('concessionaires', 'concessionaire', 'NNS'), ('for', 'for', 'IN'), ('the', 'the', 'DT'), ('purpose', 'purpose', 'NN'), ('of', 'of', 'IN'), ('keeping', 'keeping', 'VBG'), ('the', 'the', 'DT'), ('prices', 'price', 'NNS'), ('reasonable', 'reasonable', 'JJ'), ('``', '``', '``'), ('.', '.', '.')]\n",
            "\n",
            "Processed results are stored in '/gdrive/My Drive/ProcessedOutputNLTK.txt'\n"
          ]
        }
      ],
      "source": [
        "# Setting up the lemmatizer from NLTK for text processing\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# This function applies NLTK's tools to analyze sentences\n",
        "def analyze_sentence(sentence):\n",
        "    # Tokenizing the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "    # Assigning part-of-speech tags to each token\n",
        "    tagged_words = pos_tag(words)\n",
        "    # Lemmatizing each word along with its POS tag\n",
        "    lemmas_with_tags = [(word, lemmatizer.lemmatize(word), pos) for word, pos in tagged_words]\n",
        "    return lemmas_with_tags\n",
        "\n",
        "# Initiating analysis and output saving\n",
        "print(\"\\nProcessing with NLTK:\")\n",
        "output_file_path = \"/gdrive/My Drive/ProcessedOutputNLTK.txt\"\n",
        "with open(output_file_path, \"w\") as output_file:\n",
        "    index = 14  # Begin from the 14th sentence to align with student ID\n",
        "    for sentence in selected_sentences:\n",
        "        # Analyzing each sentence\n",
        "        lemma_results = analyze_sentence(sentence)\n",
        "        output_line = f\"Sentence {index} (Word, Lemma, POS): {lemma_results}\\n\"\n",
        "        print(output_line)\n",
        "        output_file.write(output_line)\n",
        "        index += 1  # Move to the next sentence\n",
        "\n",
        "print(f\"Processed results are stored in '{output_file_path}'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd35eb6",
      "metadata": {
        "id": "ddd35eb6"
      },
      "source": [
        "## spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d5d24f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86d5d24f",
        "outputId": "e9921aec-4cb5-4272-8d2b-c9062b3fa358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing with spaCy:\n",
            "Sentence 14 (Word, Lemma, POS): [('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('This', 'this', 'PRON'), ('is', 'be', 'AUX'), ('one', 'one', 'NUM'), ('of', 'of', 'ADP'), ('the', 'the', 'DET'), ('major', 'major', 'ADJ'), ('items', 'item', 'NOUN'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('Fulton', 'Fulton', 'PROPN'), ('County', 'County', 'PROPN'), ('general', 'general', 'ADJ'), ('assistance', 'assistance', 'NOUN'), ('program', 'program', 'NOUN'), (\"''\", \"''\", 'PUNCT'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('said', 'say', 'VERB'), (',', ',', 'PUNCT'), ('but', 'but', 'CCONJ'), ('the', 'the', 'DET'), ('State', 'State', 'PROPN'), ('Welfare', 'Welfare', 'PROPN'), ('Department', 'Department', 'PROPN'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('has', 'have', 'AUX'), ('seen', 'see', 'VERB'), ('fit', 'fit', 'ADJ'), ('to', 'to', 'PART'), ('distribute', 'distribute', 'VERB'), ('these', 'these', 'DET'), ('funds', 'fund', 'NOUN'), ('through', 'through', 'ADP'), ('the', 'the', 'DET'), ('welfare', 'welfare', 'NOUN'), ('departments', 'department', 'NOUN'), ('of', 'of', 'ADP'), ('all', 'all', 'DET'), ('the', 'the', 'DET'), ('counties', 'county', 'NOUN'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('state', 'state', 'NOUN'), ('with', 'with', 'ADP'), ('the', 'the', 'DET'), ('exception', 'exception', 'NOUN'), ('of', 'of', 'ADP'), ('Fulton', 'Fulton', 'PROPN'), ('County', 'County', 'PROPN'), (',', ',', 'PUNCT'), ('which', 'which', 'PRON'), ('receives', 'receive', 'VERB'), ('none', 'none', 'NOUN'), ('of', 'of', 'ADP'), ('this', 'this', 'DET'), ('money', 'money', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 15 (Word, Lemma, POS): [('The', 'the', 'DET'), ('jurors', 'juror', 'NOUN'), ('said', 'say', 'VERB'), ('they', 'they', 'PRON'), ('realize', 'realize', 'VERB'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('a', 'a', 'DET'), ('proportionate', 'proportionate', 'ADJ'), ('distribution', 'distribution', 'NOUN'), ('of', 'of', 'ADP'), ('these', 'these', 'DET'), ('funds', 'fund', 'NOUN'), ('might', 'might', 'AUX'), ('disable', 'disable', 'VERB'), ('this', 'this', 'DET'), ('program', 'program', 'NOUN'), ('in', 'in', 'ADP'), ('our', 'our', 'PRON'), ('less', 'less', 'ADV'), ('populous', 'populous', 'ADJ'), ('counties', 'county', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 16 (Word, Lemma, POS): [('Nevertheless', 'nevertheless', 'ADV'), (',', ',', 'PUNCT'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('we', 'we', 'PRON'), ('feel', 'feel', 'VERB'), ('that', 'that', 'SCONJ'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('future', 'future', 'NOUN'), ('Fulton', 'Fulton', 'PROPN'), ('County', 'County', 'PROPN'), ('should', 'should', 'AUX'), ('receive', 'receive', 'VERB'), ('some', 'some', 'DET'), ('portion', 'portion', 'NOUN'), ('of', 'of', 'ADP'), ('these', 'these', 'DET'), ('available', 'available', 'ADJ'), ('funds', 'fund', 'NOUN'), (\"''\", \"''\", 'PUNCT'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jurors', 'juror', 'NOUN'), ('said', 'say', 'VERB'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 17 (Word, Lemma, POS): [('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('Failure', 'failure', 'NOUN'), ('to', 'to', 'PART'), ('do', 'do', 'AUX'), ('this', 'this', 'PRON'), ('will', 'will', 'AUX'), ('continue', 'continue', 'VERB'), ('to', 'to', 'PART'), ('place', 'place', 'VERB'), ('a', 'a', 'DET'), ('disproportionate', 'disproportionate', 'ADJ'), ('burden', 'burden', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('on', 'on', 'ADP'), ('Fulton', 'Fulton', 'PROPN'), ('taxpayers', 'taxpayer', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 18 (Word, Lemma, POS): [('The', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('also', 'also', 'ADV'), ('commented', 'comment', 'VERB'), ('on', 'on', 'ADP'), ('the', 'the', 'DET'), ('Fulton', 'Fulton', 'PROPN'), ('ordinary', 'ordinary', 'NOUN'), (\"'s\", \"'s\", 'PART'), ('court', 'court', 'NOUN'), ('which', 'which', 'PRON'), ('has', 'have', 'AUX'), ('been', 'be', 'AUX'), ('under', 'under', 'ADP'), ('fire', 'fire', 'NOUN'), ('for', 'for', 'ADP'), ('its', 'its', 'PRON'), ('practices', 'practice', 'NOUN'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('appointment', 'appointment', 'NOUN'), ('of', 'of', 'ADP'), ('appraisers', 'appraiser', 'NOUN'), (',', ',', 'PUNCT'), ('guardians', 'guardian', 'NOUN'), ('and', 'and', 'CCONJ'), ('administrators', 'administrator', 'NOUN'), ('and', 'and', 'CCONJ'), ('the', 'the', 'DET'), ('awarding', 'awarding', 'NOUN'), ('of', 'of', 'ADP'), ('fees', 'fee', 'NOUN'), ('and', 'and', 'CCONJ'), ('compensation', 'compensation', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 19 (Word, Lemma, POS): [('Wards', 'ward', 'NOUN'), ('protected', 'protect', 'VERB')]\n",
            "\n",
            "Sentence 20 (Word, Lemma, POS): [('The', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('said', 'say', 'VERB'), ('it', 'it', 'PRON'), ('found', 'find', 'VERB'), ('the', 'the', 'DET'), ('court', 'court', 'NOUN'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('has', 'have', 'AUX'), ('incorporated', 'incorporate', 'VERB'), ('into', 'into', 'ADP'), ('its', 'its', 'PRON'), ('operating', 'operating', 'NOUN'), ('procedures', 'procedure', 'NOUN'), ('the', 'the', 'DET'), ('recommendations', 'recommendation', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('of', 'of', 'ADP'), ('two', 'two', 'NUM'), ('previous', 'previous', 'ADJ'), ('grand', 'grand', 'ADJ'), ('juries', 'jury', 'NOUN'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('Atlanta', 'Atlanta', 'PROPN'), ('Bar', 'Bar', 'PROPN'), ('Association', 'Association', 'PROPN'), ('and', 'and', 'CCONJ'), ('an', 'an', 'DET'), ('interim', 'interim', 'ADJ'), ('citizens', 'citizen', 'NOUN'), ('committee', 'committee', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 21 (Word, Lemma, POS): [('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('These', 'these', 'DET'), ('actions', 'action', 'NOUN'), ('should', 'should', 'AUX'), ('serve', 'serve', 'VERB'), ('to', 'to', 'PART'), ('protect', 'protect', 'VERB'), ('in', 'in', 'ADP'), ('fact', 'fact', 'NOUN'), ('and', 'and', 'CCONJ'), ('in', 'in', 'ADP'), ('effect', 'effect', 'NOUN'), ('the', 'the', 'DET'), ('court', 'court', 'NOUN'), (\"'s\", \"'s\", 'PART'), ('wards', 'ward', 'NOUN'), ('from', 'from', 'ADP'), ('undue', 'undue', 'ADJ'), ('costs', 'cost', 'NOUN'), ('and', 'and', 'CCONJ'), ('its', 'its', 'PRON'), ('appointed', 'appoint', 'VERB'), ('and', 'and', 'CCONJ'), ('elected', 'elect', 'VERB'), ('servants', 'servant', 'NOUN'), ('from', 'from', 'ADP'), ('unmeritorious', 'unmeritorious', 'ADJ'), ('criticisms', 'criticism', 'NOUN'), (\"''\", \"''\", 'PUNCT'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('said', 'say', 'VERB'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 22 (Word, Lemma, POS): [('Regarding', 'regard', 'VERB'), ('Atlanta', 'Atlanta', 'PROPN'), (\"'s\", \"'s\", 'PART'), ('new', 'new', 'ADJ'), ('multi', 'multi', 'ADJ'), ('-', '-', 'ADJ'), ('million', 'million', 'NUM'), ('-', '-', 'PUNCT'), ('dollar', 'dollar', 'NOUN'), ('airport', 'airport', 'NOUN'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('recommended', 'recommend', 'VERB'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('that', 'that', 'SCONJ'), ('when', 'when', 'SCONJ'), ('the', 'the', 'DET'), ('new', 'new', 'ADJ'), ('management', 'management', 'NOUN'), ('takes', 'take', 'VERB'), ('charge', 'charge', 'NOUN'), ('Jan.', 'Jan.', 'PROPN'), ('1', '1', 'NUM'), ('the', 'the', 'DET'), ('airport', 'airport', 'NOUN'), ('be', 'be', 'AUX'), ('operated', 'operate', 'VERB'), ('in', 'in', 'ADP'), ('a', 'a', 'DET'), ('manner', 'manner', 'NOUN'), ('that', 'that', 'PRON'), ('will', 'will', 'AUX'), ('eliminate', 'eliminate', 'VERB'), ('political', 'political', 'ADJ'), ('influences', 'influence', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Sentence 23 (Word, Lemma, POS): [('The', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('did', 'do', 'AUX'), ('not', 'not', 'PART'), ('elaborate', 'elaborate', 'VERB'), (',', ',', 'PUNCT'), ('but', 'but', 'CCONJ'), ('it', 'it', 'PRON'), ('added', 'add', 'VERB'), ('that', 'that', 'SCONJ'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('there', 'there', 'PRON'), ('should', 'should', 'AUX'), ('be', 'be', 'AUX'), ('periodic', 'periodic', 'ADJ'), ('surveillance', 'surveillance', 'NOUN'), ('of', 'of', 'ADP'), ('the', 'the', 'DET'), ('pricing', 'pricing', 'NOUN'), ('practices', 'practice', 'NOUN'), ('of', 'of', 'ADP'), ('the', 'the', 'DET'), ('concessionaires', 'concessionaire', 'NOUN'), ('for', 'for', 'ADP'), ('the', 'the', 'DET'), ('purpose', 'purpose', 'NOUN'), ('of', 'of', 'ADP'), ('keeping', 'keep', 'VERB'), ('the', 'the', 'DET'), ('prices', 'price', 'NOUN'), ('reasonable', 'reasonable', 'ADJ'), (\"''\", \"''\", 'PUNCT'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "Analysis completed. Results saved to '/gdrive/My Drive/spaCyAnalysisResults.txt'\n"
          ]
        }
      ],
      "source": [
        "# Setup for text analysis using spaCy\n",
        "def analyze_text_spacy(sentence):\n",
        "    document = nlp(sentence)\n",
        "    analysis_results = [(token.text, token.lemma_, token.pos_) for token in document]\n",
        "    return analysis_results\n",
        "\n",
        "# Begin text analysis using spaCy and save the results\n",
        "print(\"\\nAnalyzing with spaCy:\")\n",
        "output_file_name = \"/gdrive/My Drive/spaCyAnalysisResults.txt\"\n",
        "with open(output_file_name, \"w\") as file:\n",
        "    sentence_counter = 14  # Initial sentence index as per student ID requirements\n",
        "    for sentence in selected_sentences:\n",
        "        analysis_outcome = analyze_text_spacy(sentence)\n",
        "        formatted_output = f\"Sentence {sentence_counter} (Word, Lemma, POS): {analysis_outcome}\\n\"\n",
        "        print(formatted_output)  # Display the formatted output\n",
        "        file.write(formatted_output)  # Save the formatted output to a file\n",
        "        sentence_counter += 1  # Prepare for the next sentence\n",
        "\n",
        "print(f\"Analysis completed. Results saved to '{output_file_name}'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "284b4b4d",
      "metadata": {
        "id": "284b4b4d"
      },
      "source": [
        "## Comparison\n",
        "\n",
        "To address the comparison of NLTK and spaCy in terms of Part-of-Speech (POS) tagging and lemmatization, we can implement a qualitative review process using Python. This involves:\n",
        "\n",
        "1. **Extracting the original POS tags** from the Brown Corpus for our selected sentences to serve as a reference.\n",
        "2. **Reviewing the POS tags and lemmatization** outputs from both NLTK and spaCy.\n",
        "3. **Identifying core differences and limitations** in the outputs, focusing on noticeable patterns or discrepancies rather than evaluating every single token.\n",
        "\n",
        "We'll start by extracting the original POS tags for the selected sentences from the Brown Corpus. Then, we'll load the outputs from both NLTK and spaCy, and compare these outputs with the original tags to observe any significant differences or patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a84722",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73a84722",
        "outputId": "8880038f-fed6-4f80-8ef0-80d9be2d7f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original POS tags have been successfully saved to 'OriginalPOSTagsAnalysis.txt'\n"
          ]
        }
      ],
      "source": [
        "# Retrieve and document the original POS tags from the Brown Corpus for comparison\n",
        "original_tags_collection = [brown.tagged_sents(categories='news')[index] for index in range(14, 24)]\n",
        "\n",
        "# Documenting the original POS tags for subsequent analysis\n",
        "with open(\"/gdrive/My Drive/OriginalPOSTagsAnalysis.txt\", \"w\") as tags_file:\n",
        "    sentence_number = 14  # Commencing from the 14th sentence for alignment with specifics\n",
        "    for tagged_sent in original_tags_collection:\n",
        "        tags_file.write(f\"Sentence {sentence_number}: {tagged_sent}\\n\")\n",
        "        sentence_number += 1  # Advancing to the next sentence\n",
        "\n",
        "print(\"Original POS tags have been successfully saved to 'OriginalPOSTagsAnalysis.txt'\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80cbcc74",
      "metadata": {
        "id": "80cbcc74"
      },
      "source": [
        "### Load NLTK and spaCy Outputs for Comparison\n",
        "\n",
        "We'll read back the outputs from the NLTK and spaCy processed files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480e354f",
      "metadata": {
        "id": "480e354f"
      },
      "outputs": [],
      "source": [
        "# Processing sentences to gather NLTK and spaCy linguistic annotations\n",
        "nltk_annotated = [analyze_sentence(sentence) for sentence in selected_sentences]\n",
        "spacy_annotated = [analyze_text_spacy(sentence) for sentence in selected_sentences]\n",
        "\n",
        "# Adjusting the original POS tags from the Brown Corpus for a unified comparison\n",
        "adjusted_pos_tags = [\n",
        "    [(token, '', tag) for token, tag in tagged_sent]\n",
        "    for tagged_sent in original_tags_collection\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e019066",
      "metadata": {
        "id": "4e019066"
      },
      "source": [
        "### Comparison Overview\n",
        "\n",
        "- **POS Tagging:** Juxtapose the POS tags from NLTK and spaCy against Brown's original tags to identify variances.\n",
        "- **Lemmatization:** Without lemmatized forms in Brown, the evaluation will be subjective, focusing on inaccuracies or divergences in lemmatization between the frameworks.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4626fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d4626fb",
        "outputId": "07661ff4-7626-4728-9087-deb9d36230c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing Sentence 14 - Details:\n",
            "Baseline from Corpus: [('``', '', '``'), ('This', '', 'DT'), ('is', '', 'BEZ'), ('one', '', 'CD'), ('of', '', 'IN'), ('the', '', 'AT'), ('major', '', 'JJ'), ('items', '', 'NNS'), ('in', '', 'IN'), ('the', '', 'AT'), ('Fulton', '', 'NP-TL'), ('County', '', 'NN-TL'), ('general', '', 'JJ'), ('assistance', '', 'NN'), ('program', '', 'NN'), (\"''\", '', \"''\"), (',', '', ','), ('the', '', 'AT'), ('jury', '', 'NN'), ('said', '', 'VBD'), (',', '', ','), ('but', '', 'CC'), ('the', '', 'AT'), ('State', '', 'NN-TL'), ('Welfare', '', 'NN-TL'), ('Department', '', 'NN-TL'), ('``', '', '``'), ('has', '', 'HVZ'), ('seen', '', 'VBN'), ('fit', '', 'JJ'), ('to', '', 'TO'), ('distribute', '', 'VB'), ('these', '', 'DTS'), ('funds', '', 'NNS'), ('through', '', 'IN'), ('the', '', 'AT'), ('welfare', '', 'NN'), ('departments', '', 'NNS'), ('of', '', 'IN'), ('all', '', 'ABN'), ('the', '', 'AT'), ('counties', '', 'NNS'), ('in', '', 'IN'), ('the', '', 'AT'), ('state', '', 'NN'), ('with', '', 'IN'), ('the', '', 'AT'), ('exception', '', 'NN'), ('of', '', 'IN'), ('Fulton', '', 'NP-TL'), ('County', '', 'NN-TL'), (',', '', ','), ('which', '', 'WDT'), ('receives', '', 'VBZ'), ('none', '', 'PN'), ('of', '', 'IN'), ('this', '', 'DT'), ('money', '', 'NN'), ('.', '', '.')]\n",
            "Results via NLTK: [('``', '``', '``'), ('This', 'This', 'DT'), ('is', 'is', 'VBZ'), ('one', 'one', 'CD'), ('of', 'of', 'IN'), ('the', 'the', 'DT'), ('major', 'major', 'JJ'), ('items', 'item', 'NNS'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('Fulton', 'Fulton', 'NNP'), ('County', 'County', 'NNP'), ('general', 'general', 'JJ'), ('assistance', 'assistance', 'NN'), ('program', 'program', 'NN'), ('``', '``', '``'), (',', ',', ','), ('the', 'the', 'DT'), ('jury', 'jury', 'NN'), ('said', 'said', 'VBD'), (',', ',', ','), ('but', 'but', 'CC'), ('the', 'the', 'DT'), ('State', 'State', 'NNP'), ('Welfare', 'Welfare', 'NNP'), ('Department', 'Department', 'NNP'), ('``', '``', '``'), ('has', 'ha', 'VBZ'), ('seen', 'seen', 'VBN'), ('fit', 'fit', 'NN'), ('to', 'to', 'TO'), ('distribute', 'distribute', 'VB'), ('these', 'these', 'DT'), ('funds', 'fund', 'NNS'), ('through', 'through', 'IN'), ('the', 'the', 'DT'), ('welfare', 'welfare', 'NN'), ('departments', 'department', 'NNS'), ('of', 'of', 'IN'), ('all', 'all', 'PDT'), ('the', 'the', 'DT'), ('counties', 'county', 'NNS'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('state', 'state', 'NN'), ('with', 'with', 'IN'), ('the', 'the', 'DT'), ('exception', 'exception', 'NN'), ('of', 'of', 'IN'), ('Fulton', 'Fulton', 'NNP'), ('County', 'County', 'NNP'), (',', ',', ','), ('which', 'which', 'WDT'), ('receives', 'receives', 'VBZ'), ('none', 'none', 'NN'), ('of', 'of', 'IN'), ('this', 'this', 'DT'), ('money', 'money', 'NN'), ('.', '.', '.')]\n",
            "Results via spaCy: [('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('This', 'this', 'PRON'), ('is', 'be', 'AUX'), ('one', 'one', 'NUM'), ('of', 'of', 'ADP'), ('the', 'the', 'DET'), ('major', 'major', 'ADJ'), ('items', 'item', 'NOUN'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('Fulton', 'Fulton', 'PROPN'), ('County', 'County', 'PROPN'), ('general', 'general', 'ADJ'), ('assistance', 'assistance', 'NOUN'), ('program', 'program', 'NOUN'), (\"''\", \"''\", 'PUNCT'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('said', 'say', 'VERB'), (',', ',', 'PUNCT'), ('but', 'but', 'CCONJ'), ('the', 'the', 'DET'), ('State', 'State', 'PROPN'), ('Welfare', 'Welfare', 'PROPN'), ('Department', 'Department', 'PROPN'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('has', 'have', 'AUX'), ('seen', 'see', 'VERB'), ('fit', 'fit', 'ADJ'), ('to', 'to', 'PART'), ('distribute', 'distribute', 'VERB'), ('these', 'these', 'DET'), ('funds', 'fund', 'NOUN'), ('through', 'through', 'ADP'), ('the', 'the', 'DET'), ('welfare', 'welfare', 'NOUN'), ('departments', 'department', 'NOUN'), ('of', 'of', 'ADP'), ('all', 'all', 'DET'), ('the', 'the', 'DET'), ('counties', 'county', 'NOUN'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('state', 'state', 'NOUN'), ('with', 'with', 'ADP'), ('the', 'the', 'DET'), ('exception', 'exception', 'NOUN'), ('of', 'of', 'ADP'), ('Fulton', 'Fulton', 'PROPN'), ('County', 'County', 'PROPN'), (',', ',', 'PUNCT'), ('which', 'which', 'PRON'), ('receives', 'receive', 'VERB'), ('none', 'none', 'NOUN'), ('of', 'of', 'ADP'), ('this', 'this', 'DET'), ('money', 'money', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 15 - Details:\n",
            "Baseline from Corpus: [('The', '', 'AT'), ('jurors', '', 'NNS'), ('said', '', 'VBD'), ('they', '', 'PPSS'), ('realize', '', 'VB'), ('``', '', '``'), ('a', '', 'AT'), ('proportionate', '', 'JJ'), ('distribution', '', 'NN'), ('of', '', 'IN'), ('these', '', 'DTS'), ('funds', '', 'NNS'), ('might', '', 'MD'), ('disable', '', 'VB'), ('this', '', 'DT'), ('program', '', 'NN'), ('in', '', 'IN'), ('our', '', 'PP$'), ('less', '', 'QL'), ('populous', '', 'JJ'), ('counties', '', 'NNS'), (\"''\", '', \"''\"), ('.', '', '.')]\n",
            "Results via NLTK: [('The', 'The', 'DT'), ('jurors', 'juror', 'NNS'), ('said', 'said', 'VBD'), ('they', 'they', 'PRP'), ('realize', 'realize', 'VBP'), ('``', '``', '``'), ('a', 'a', 'DT'), ('proportionate', 'proportionate', 'JJ'), ('distribution', 'distribution', 'NN'), ('of', 'of', 'IN'), ('these', 'these', 'DT'), ('funds', 'fund', 'NNS'), ('might', 'might', 'MD'), ('disable', 'disable', 'VB'), ('this', 'this', 'DT'), ('program', 'program', 'NN'), ('in', 'in', 'IN'), ('our', 'our', 'PRP$'), ('less', 'le', 'CC'), ('populous', 'populous', 'JJ'), ('counties', 'county', 'NNS'), ('``', '``', '``'), ('.', '.', '.')]\n",
            "Results via spaCy: [('The', 'the', 'DET'), ('jurors', 'juror', 'NOUN'), ('said', 'say', 'VERB'), ('they', 'they', 'PRON'), ('realize', 'realize', 'VERB'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('a', 'a', 'DET'), ('proportionate', 'proportionate', 'ADJ'), ('distribution', 'distribution', 'NOUN'), ('of', 'of', 'ADP'), ('these', 'these', 'DET'), ('funds', 'fund', 'NOUN'), ('might', 'might', 'AUX'), ('disable', 'disable', 'VERB'), ('this', 'this', 'DET'), ('program', 'program', 'NOUN'), ('in', 'in', 'ADP'), ('our', 'our', 'PRON'), ('less', 'less', 'ADV'), ('populous', 'populous', 'ADJ'), ('counties', 'county', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 16 - Details:\n",
            "Baseline from Corpus: [('Nevertheless', '', 'RB'), (',', '', ','), ('``', '', '``'), ('we', '', 'PPSS'), ('feel', '', 'VB'), ('that', '', 'CS'), ('in', '', 'IN'), ('the', '', 'AT'), ('future', '', 'NN'), ('Fulton', '', 'NP-TL'), ('County', '', 'NN-TL'), ('should', '', 'MD'), ('receive', '', 'VB'), ('some', '', 'DTI'), ('portion', '', 'NN'), ('of', '', 'IN'), ('these', '', 'DTS'), ('available', '', 'JJ'), ('funds', '', 'NNS'), (\"''\", '', \"''\"), (',', '', ','), ('the', '', 'AT'), ('jurors', '', 'NNS'), ('said', '', 'VBD'), ('.', '', '.')]\n",
            "Results via NLTK: [('Nevertheless', 'Nevertheless', 'RB'), (',', ',', ','), ('``', '``', '``'), ('we', 'we', 'PRP'), ('feel', 'feel', 'VBP'), ('that', 'that', 'IN'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('future', 'future', 'JJ'), ('Fulton', 'Fulton', 'NNP'), ('County', 'County', 'NNP'), ('should', 'should', 'MD'), ('receive', 'receive', 'VB'), ('some', 'some', 'DT'), ('portion', 'portion', 'NN'), ('of', 'of', 'IN'), ('these', 'these', 'DT'), ('available', 'available', 'JJ'), ('funds', 'fund', 'NNS'), ('``', '``', '``'), (',', ',', ','), ('the', 'the', 'DT'), ('jurors', 'juror', 'NNS'), ('said', 'said', 'VBD'), ('.', '.', '.')]\n",
            "Results via spaCy: [('Nevertheless', 'nevertheless', 'ADV'), (',', ',', 'PUNCT'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('we', 'we', 'PRON'), ('feel', 'feel', 'VERB'), ('that', 'that', 'SCONJ'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('future', 'future', 'NOUN'), ('Fulton', 'Fulton', 'PROPN'), ('County', 'County', 'PROPN'), ('should', 'should', 'AUX'), ('receive', 'receive', 'VERB'), ('some', 'some', 'DET'), ('portion', 'portion', 'NOUN'), ('of', 'of', 'ADP'), ('these', 'these', 'DET'), ('available', 'available', 'ADJ'), ('funds', 'fund', 'NOUN'), (\"''\", \"''\", 'PUNCT'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jurors', 'juror', 'NOUN'), ('said', 'say', 'VERB'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 17 - Details:\n",
            "Baseline from Corpus: [('``', '', '``'), ('Failure', '', 'NN'), ('to', '', 'TO'), ('do', '', 'DO'), ('this', '', 'DT'), ('will', '', 'MD'), ('continue', '', 'VB'), ('to', '', 'TO'), ('place', '', 'VB'), ('a', '', 'AT'), ('disproportionate', '', 'JJ'), ('burden', '', 'NN'), (\"''\", '', \"''\"), ('on', '', 'IN'), ('Fulton', '', 'NP'), ('taxpayers', '', 'NNS'), ('.', '', '.')]\n",
            "Results via NLTK: [('``', '``', '``'), ('Failure', 'Failure', 'NN'), ('to', 'to', 'TO'), ('do', 'do', 'VB'), ('this', 'this', 'DT'), ('will', 'will', 'MD'), ('continue', 'continue', 'VB'), ('to', 'to', 'TO'), ('place', 'place', 'VB'), ('a', 'a', 'DT'), ('disproportionate', 'disproportionate', 'NN'), ('burden', 'burden', 'NN'), ('``', '``', '``'), ('on', 'on', 'IN'), ('Fulton', 'Fulton', 'NNP'), ('taxpayers', 'taxpayer', 'NNS'), ('.', '.', '.')]\n",
            "Results via spaCy: [('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('Failure', 'failure', 'NOUN'), ('to', 'to', 'PART'), ('do', 'do', 'AUX'), ('this', 'this', 'PRON'), ('will', 'will', 'AUX'), ('continue', 'continue', 'VERB'), ('to', 'to', 'PART'), ('place', 'place', 'VERB'), ('a', 'a', 'DET'), ('disproportionate', 'disproportionate', 'ADJ'), ('burden', 'burden', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('on', 'on', 'ADP'), ('Fulton', 'Fulton', 'PROPN'), ('taxpayers', 'taxpayer', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 18 - Details:\n",
            "Baseline from Corpus: [('The', '', 'AT'), ('jury', '', 'NN'), ('also', '', 'RB'), ('commented', '', 'VBD'), ('on', '', 'IN'), ('the', '', 'AT'), ('Fulton', '', 'NP'), (\"ordinary's\", '', 'NN$'), ('court', '', 'NN'), ('which', '', 'WDT'), ('has', '', 'HVZ'), ('been', '', 'BEN'), ('under', '', 'IN'), ('fire', '', 'NN'), ('for', '', 'IN'), ('its', '', 'PP$'), ('practices', '', 'NNS'), ('in', '', 'IN'), ('the', '', 'AT'), ('appointment', '', 'NN'), ('of', '', 'IN'), ('appraisers', '', 'NNS'), (',', '', ','), ('guardians', '', 'NNS'), ('and', '', 'CC'), ('administrators', '', 'NNS'), ('and', '', 'CC'), ('the', '', 'AT'), ('awarding', '', 'NN'), ('of', '', 'IN'), ('fees', '', 'NNS'), ('and', '', 'CC'), ('compensation', '', 'NN'), ('.', '', '.')]\n",
            "Results via NLTK: [('The', 'The', 'DT'), ('jury', 'jury', 'NN'), ('also', 'also', 'RB'), ('commented', 'commented', 'VBN'), ('on', 'on', 'IN'), ('the', 'the', 'DT'), ('Fulton', 'Fulton', 'NNP'), ('ordinary', 'ordinary', 'NNP'), (\"'s\", \"'s\", 'POS'), ('court', 'court', 'NN'), ('which', 'which', 'WDT'), ('has', 'ha', 'VBZ'), ('been', 'been', 'VBN'), ('under', 'under', 'IN'), ('fire', 'fire', 'NN'), ('for', 'for', 'IN'), ('its', 'it', 'PRP$'), ('practices', 'practice', 'NNS'), ('in', 'in', 'IN'), ('the', 'the', 'DT'), ('appointment', 'appointment', 'NN'), ('of', 'of', 'IN'), ('appraisers', 'appraiser', 'NNS'), (',', ',', ','), ('guardians', 'guardian', 'NNS'), ('and', 'and', 'CC'), ('administrators', 'administrator', 'NNS'), ('and', 'and', 'CC'), ('the', 'the', 'DT'), ('awarding', 'awarding', 'NN'), ('of', 'of', 'IN'), ('fees', 'fee', 'NNS'), ('and', 'and', 'CC'), ('compensation', 'compensation', 'NN'), ('.', '.', '.')]\n",
            "Results via spaCy: [('The', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('also', 'also', 'ADV'), ('commented', 'comment', 'VERB'), ('on', 'on', 'ADP'), ('the', 'the', 'DET'), ('Fulton', 'Fulton', 'PROPN'), ('ordinary', 'ordinary', 'NOUN'), (\"'s\", \"'s\", 'PART'), ('court', 'court', 'NOUN'), ('which', 'which', 'PRON'), ('has', 'have', 'AUX'), ('been', 'be', 'AUX'), ('under', 'under', 'ADP'), ('fire', 'fire', 'NOUN'), ('for', 'for', 'ADP'), ('its', 'its', 'PRON'), ('practices', 'practice', 'NOUN'), ('in', 'in', 'ADP'), ('the', 'the', 'DET'), ('appointment', 'appointment', 'NOUN'), ('of', 'of', 'ADP'), ('appraisers', 'appraiser', 'NOUN'), (',', ',', 'PUNCT'), ('guardians', 'guardian', 'NOUN'), ('and', 'and', 'CCONJ'), ('administrators', 'administrator', 'NOUN'), ('and', 'and', 'CCONJ'), ('the', 'the', 'DET'), ('awarding', 'awarding', 'NOUN'), ('of', 'of', 'ADP'), ('fees', 'fee', 'NOUN'), ('and', 'and', 'CCONJ'), ('compensation', 'compensation', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 19 - Details:\n",
            "Baseline from Corpus: [('Wards', '', 'NNS-HL'), ('protected', '', 'VBN-HL')]\n",
            "Results via NLTK: [('Wards', 'Wards', 'NNS'), ('protected', 'protected', 'VBD')]\n",
            "Results via spaCy: [('Wards', 'ward', 'NOUN'), ('protected', 'protect', 'VERB')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 20 - Details:\n",
            "Baseline from Corpus: [('The', '', 'AT'), ('jury', '', 'NN'), ('said', '', 'VBD'), ('it', '', 'PPS'), ('found', '', 'VBD'), ('the', '', 'AT'), ('court', '', 'NN'), ('``', '', '``'), ('has', '', 'HVZ'), ('incorporated', '', 'VBN'), ('into', '', 'IN'), ('its', '', 'PP$'), ('operating', '', 'VBG'), ('procedures', '', 'NNS'), ('the', '', 'AT'), ('recommendations', '', 'NNS'), (\"''\", '', \"''\"), ('of', '', 'IN'), ('two', '', 'CD'), ('previous', '', 'JJ'), ('grand', '', 'JJ'), ('juries', '', 'NNS'), (',', '', ','), ('the', '', 'AT'), ('Atlanta', '', 'NP-TL'), ('Bar', '', 'NN-TL'), ('Association', '', 'NN-TL'), ('and', '', 'CC'), ('an', '', 'AT'), ('interim', '', 'NN'), ('citizens', '', 'NNS'), ('committee', '', 'NN'), ('.', '', '.')]\n",
            "Results via NLTK: [('The', 'The', 'DT'), ('jury', 'jury', 'NN'), ('said', 'said', 'VBD'), ('it', 'it', 'PRP'), ('found', 'found', 'VBD'), ('the', 'the', 'DT'), ('court', 'court', 'NN'), ('``', '``', '``'), ('has', 'ha', 'VBZ'), ('incorporated', 'incorporated', 'VBN'), ('into', 'into', 'IN'), ('its', 'it', 'PRP$'), ('operating', 'operating', 'NN'), ('procedures', 'procedure', 'VBZ'), ('the', 'the', 'DT'), ('recommendations', 'recommendation', 'NNS'), ('``', '``', '``'), ('of', 'of', 'IN'), ('two', 'two', 'CD'), ('previous', 'previous', 'JJ'), ('grand', 'grand', 'JJ'), ('juries', 'jury', 'NNS'), (',', ',', ','), ('the', 'the', 'DT'), ('Atlanta', 'Atlanta', 'NNP'), ('Bar', 'Bar', 'NNP'), ('Association', 'Association', 'NNP'), ('and', 'and', 'CC'), ('an', 'an', 'DT'), ('interim', 'interim', 'JJ'), ('citizens', 'citizen', 'NNS'), ('committee', 'committee', 'NN'), ('.', '.', '.')]\n",
            "Results via spaCy: [('The', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('said', 'say', 'VERB'), ('it', 'it', 'PRON'), ('found', 'find', 'VERB'), ('the', 'the', 'DET'), ('court', 'court', 'NOUN'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('has', 'have', 'AUX'), ('incorporated', 'incorporate', 'VERB'), ('into', 'into', 'ADP'), ('its', 'its', 'PRON'), ('operating', 'operating', 'NOUN'), ('procedures', 'procedure', 'NOUN'), ('the', 'the', 'DET'), ('recommendations', 'recommendation', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('of', 'of', 'ADP'), ('two', 'two', 'NUM'), ('previous', 'previous', 'ADJ'), ('grand', 'grand', 'ADJ'), ('juries', 'jury', 'NOUN'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('Atlanta', 'Atlanta', 'PROPN'), ('Bar', 'Bar', 'PROPN'), ('Association', 'Association', 'PROPN'), ('and', 'and', 'CCONJ'), ('an', 'an', 'DET'), ('interim', 'interim', 'ADJ'), ('citizens', 'citizen', 'NOUN'), ('committee', 'committee', 'NOUN'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 21 - Details:\n",
            "Baseline from Corpus: [('``', '', '``'), ('These', '', 'DTS'), ('actions', '', 'NNS'), ('should', '', 'MD'), ('serve', '', 'VB'), ('to', '', 'TO'), ('protect', '', 'VB'), ('in', '', 'IN'), ('fact', '', 'NN'), ('and', '', 'CC'), ('in', '', 'IN'), ('effect', '', 'NN'), ('the', '', 'AT'), (\"court's\", '', 'NN$'), ('wards', '', 'NNS'), ('from', '', 'IN'), ('undue', '', 'JJ'), ('costs', '', 'NNS'), ('and', '', 'CC'), ('its', '', 'PP$'), ('appointed', '', 'VBN'), ('and', '', 'CC'), ('elected', '', 'VBN'), ('servants', '', 'NNS'), ('from', '', 'IN'), ('unmeritorious', '', 'JJ'), ('criticisms', '', 'NNS'), (\"''\", '', \"''\"), (',', '', ','), ('the', '', 'AT'), ('jury', '', 'NN'), ('said', '', 'VBD'), ('.', '', '.')]\n",
            "Results via NLTK: [('``', '``', '``'), ('These', 'These', 'DT'), ('actions', 'action', 'NNS'), ('should', 'should', 'MD'), ('serve', 'serve', 'VB'), ('to', 'to', 'TO'), ('protect', 'protect', 'VB'), ('in', 'in', 'IN'), ('fact', 'fact', 'NN'), ('and', 'and', 'CC'), ('in', 'in', 'IN'), ('effect', 'effect', 'NN'), ('the', 'the', 'DT'), ('court', 'court', 'NN'), (\"'s\", \"'s\", 'POS'), ('wards', 'ward', 'NNS'), ('from', 'from', 'IN'), ('undue', 'undue', 'JJ'), ('costs', 'cost', 'NNS'), ('and', 'and', 'CC'), ('its', 'it', 'PRP$'), ('appointed', 'appointed', 'VBN'), ('and', 'and', 'CC'), ('elected', 'elected', 'VBN'), ('servants', 'servant', 'NNS'), ('from', 'from', 'IN'), ('unmeritorious', 'unmeritorious', 'JJ'), ('criticisms', 'criticism', 'NNS'), ('``', '``', '``'), (',', ',', ','), ('the', 'the', 'DT'), ('jury', 'jury', 'NN'), ('said', 'said', 'VBD'), ('.', '.', '.')]\n",
            "Results via spaCy: [('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('These', 'these', 'DET'), ('actions', 'action', 'NOUN'), ('should', 'should', 'AUX'), ('serve', 'serve', 'VERB'), ('to', 'to', 'PART'), ('protect', 'protect', 'VERB'), ('in', 'in', 'ADP'), ('fact', 'fact', 'NOUN'), ('and', 'and', 'CCONJ'), ('in', 'in', 'ADP'), ('effect', 'effect', 'NOUN'), ('the', 'the', 'DET'), ('court', 'court', 'NOUN'), (\"'s\", \"'s\", 'PART'), ('wards', 'ward', 'NOUN'), ('from', 'from', 'ADP'), ('undue', 'undue', 'ADJ'), ('costs', 'cost', 'NOUN'), ('and', 'and', 'CCONJ'), ('its', 'its', 'PRON'), ('appointed', 'appoint', 'VERB'), ('and', 'and', 'CCONJ'), ('elected', 'elect', 'VERB'), ('servants', 'servant', 'NOUN'), ('from', 'from', 'ADP'), ('unmeritorious', 'unmeritorious', 'ADJ'), ('criticisms', 'criticism', 'NOUN'), (\"''\", \"''\", 'PUNCT'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('said', 'say', 'VERB'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 22 - Details:\n",
            "Baseline from Corpus: [('Regarding', '', 'IN'), (\"Atlanta's\", '', 'NP$'), ('new', '', 'JJ'), ('multi-million-dollar', '', 'JJ'), ('airport', '', 'NN'), (',', '', ','), ('the', '', 'AT'), ('jury', '', 'NN'), ('recommended', '', 'VBD'), ('``', '', '``'), ('that', '', 'CS'), ('when', '', 'WRB'), ('the', '', 'AT'), ('new', '', 'JJ'), ('management', '', 'NN'), ('takes', '', 'VBZ'), ('charge', '', 'NN'), ('Jan.', '', 'NP'), ('1', '', 'CD'), ('the', '', 'AT'), ('airport', '', 'NN'), ('be', '', 'BE'), ('operated', '', 'VBN'), ('in', '', 'IN'), ('a', '', 'AT'), ('manner', '', 'NN'), ('that', '', 'WPS'), ('will', '', 'MD'), ('eliminate', '', 'VB'), ('political', '', 'JJ'), ('influences', '', 'NNS'), (\"''\", '', \"''\"), ('.', '', '.')]\n",
            "Results via NLTK: [('Regarding', 'Regarding', 'VBG'), ('Atlanta', 'Atlanta', 'NNP'), (\"'s\", \"'s\", 'POS'), ('new', 'new', 'JJ'), ('multi-million-dollar', 'multi-million-dollar', 'JJ'), ('airport', 'airport', 'NN'), (',', ',', ','), ('the', 'the', 'DT'), ('jury', 'jury', 'NN'), ('recommended', 'recommended', 'VBD'), ('``', '``', '``'), ('that', 'that', 'IN'), ('when', 'when', 'WRB'), ('the', 'the', 'DT'), ('new', 'new', 'JJ'), ('management', 'management', 'NN'), ('takes', 'take', 'VBZ'), ('charge', 'charge', 'NN'), ('Jan.', 'Jan.', 'NNP'), ('1', '1', 'CD'), ('the', 'the', 'DT'), ('airport', 'airport', 'NN'), ('be', 'be', 'VB'), ('operated', 'operated', 'VBN'), ('in', 'in', 'IN'), ('a', 'a', 'DT'), ('manner', 'manner', 'NN'), ('that', 'that', 'WDT'), ('will', 'will', 'MD'), ('eliminate', 'eliminate', 'VB'), ('political', 'political', 'JJ'), ('influences', 'influence', 'NNS'), ('``', '``', '``'), ('.', '.', '.')]\n",
            "Results via spaCy: [('Regarding', 'regard', 'VERB'), ('Atlanta', 'Atlanta', 'PROPN'), (\"'s\", \"'s\", 'PART'), ('new', 'new', 'ADJ'), ('multi', 'multi', 'ADJ'), ('-', '-', 'ADJ'), ('million', 'million', 'NUM'), ('-', '-', 'PUNCT'), ('dollar', 'dollar', 'NOUN'), ('airport', 'airport', 'NOUN'), (',', ',', 'PUNCT'), ('the', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('recommended', 'recommend', 'VERB'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('that', 'that', 'SCONJ'), ('when', 'when', 'SCONJ'), ('the', 'the', 'DET'), ('new', 'new', 'ADJ'), ('management', 'management', 'NOUN'), ('takes', 'take', 'VERB'), ('charge', 'charge', 'NOUN'), ('Jan.', 'Jan.', 'PROPN'), ('1', '1', 'NUM'), ('the', 'the', 'DET'), ('airport', 'airport', 'NOUN'), ('be', 'be', 'AUX'), ('operated', 'operate', 'VERB'), ('in', 'in', 'ADP'), ('a', 'a', 'DET'), ('manner', 'manner', 'NOUN'), ('that', 'that', 'PRON'), ('will', 'will', 'AUX'), ('eliminate', 'eliminate', 'VERB'), ('political', 'political', 'ADJ'), ('influences', 'influence', 'NOUN'), (\"''\", \"''\", 'PUNCT'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n",
            "Analyzing Sentence 23 - Details:\n",
            "Baseline from Corpus: [('The', '', 'AT'), ('jury', '', 'NN'), ('did', '', 'DOD'), ('not', '', '*'), ('elaborate', '', 'VB'), (',', '', ','), ('but', '', 'CC'), ('it', '', 'PPS'), ('added', '', 'VBD'), ('that', '', 'CS'), ('``', '', '``'), ('there', '', 'EX'), ('should', '', 'MD'), ('be', '', 'BE'), ('periodic', '', 'JJ'), ('surveillance', '', 'NN'), ('of', '', 'IN'), ('the', '', 'AT'), ('pricing', '', 'VBG'), ('practices', '', 'NNS'), ('of', '', 'IN'), ('the', '', 'AT'), ('concessionaires', '', 'NNS'), ('for', '', 'IN'), ('the', '', 'AT'), ('purpose', '', 'NN'), ('of', '', 'IN'), ('keeping', '', 'VBG'), ('the', '', 'AT'), ('prices', '', 'NNS'), ('reasonable', '', 'JJ'), (\"''\", '', \"''\"), ('.', '', '.')]\n",
            "Results via NLTK: [('The', 'The', 'DT'), ('jury', 'jury', 'NN'), ('did', 'did', 'VBD'), ('not', 'not', 'RB'), ('elaborate', 'elaborate', 'JJ'), (',', ',', ','), ('but', 'but', 'CC'), ('it', 'it', 'PRP'), ('added', 'added', 'VBD'), ('that', 'that', 'IN'), ('``', '``', '``'), ('there', 'there', 'EX'), ('should', 'should', 'MD'), ('be', 'be', 'VB'), ('periodic', 'periodic', 'JJ'), ('surveillance', 'surveillance', 'NN'), ('of', 'of', 'IN'), ('the', 'the', 'DT'), ('pricing', 'pricing', 'NN'), ('practices', 'practice', 'NNS'), ('of', 'of', 'IN'), ('the', 'the', 'DT'), ('concessionaires', 'concessionaire', 'NNS'), ('for', 'for', 'IN'), ('the', 'the', 'DT'), ('purpose', 'purpose', 'NN'), ('of', 'of', 'IN'), ('keeping', 'keeping', 'VBG'), ('the', 'the', 'DT'), ('prices', 'price', 'NNS'), ('reasonable', 'reasonable', 'JJ'), ('``', '``', '``'), ('.', '.', '.')]\n",
            "Results via spaCy: [('The', 'the', 'DET'), ('jury', 'jury', 'NOUN'), ('did', 'do', 'AUX'), ('not', 'not', 'PART'), ('elaborate', 'elaborate', 'VERB'), (',', ',', 'PUNCT'), ('but', 'but', 'CCONJ'), ('it', 'it', 'PRON'), ('added', 'add', 'VERB'), ('that', 'that', 'SCONJ'), ('`', '`', 'PUNCT'), ('`', '`', 'PUNCT'), ('there', 'there', 'PRON'), ('should', 'should', 'AUX'), ('be', 'be', 'AUX'), ('periodic', 'periodic', 'ADJ'), ('surveillance', 'surveillance', 'NOUN'), ('of', 'of', 'ADP'), ('the', 'the', 'DET'), ('pricing', 'pricing', 'NOUN'), ('practices', 'practice', 'NOUN'), ('of', 'of', 'ADP'), ('the', 'the', 'DET'), ('concessionaires', 'concessionaire', 'NOUN'), ('for', 'for', 'ADP'), ('the', 'the', 'DET'), ('purpose', 'purpose', 'NOUN'), ('of', 'of', 'ADP'), ('keeping', 'keep', 'VERB'), ('the', 'the', 'DET'), ('prices', 'price', 'NOUN'), ('reasonable', 'reasonable', 'ADJ'), (\"''\", \"''\", 'PUNCT'), ('.', '.', 'PUNCT')]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example code for reviewing POS tags and lemmatization\n",
        "for sentence_counter in range(10):\n",
        "    sentence_id = 14 + sentence_counter\n",
        "    print(f\"Analyzing Sentence {sentence_id} - Details:\")\n",
        "    print(f\"Baseline from Corpus: {adjusted_pos_tags[sentence_counter]}\")\n",
        "    print(f\"Results via NLTK: {nltk_annotated[sentence_counter]}\")\n",
        "    print(f\"Results via spaCy: {spacy_annotated[sentence_counter]}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c247c3b",
      "metadata": {
        "id": "9c247c3b"
      },
      "source": [
        "This conceptual approach allows for a manual review of the frameworks' outputs. The following questions may be considered:\n",
        "\n",
        "- **POS Tagging Differences:** Are there tags where one framework consistently differs from the original Brown tags or the other framework?\n",
        "- **Lemmatization Differences:** Does one framework appear to produce more accurate or contextually appropriate lemmas than the other?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a2019ed",
      "metadata": {
        "id": "5a2019ed"
      },
      "source": [
        "### Save the Outputs\n",
        "\n",
        "Given the detailed nature of the outputs, which include original tags, NLTK outputs, and spaCy outputs, a structured file format that supports hierarchy and is easily readable for both humans and machines is preferable. JSON (JavaScript Object Notation) is an ideal choice for this purpose because:\n",
        "\n",
        "- **It can easily represent the nested structure of sentences, POS tags, and lemmatization outputs.**\n",
        "- **It's widely supported and can be easily read into most data analysis tools, programming languages, and libraries.**\n",
        "- **It facilitates a straightforward comparison of complex structures.**\n",
        "\n",
        "This code will structure the data accordingly and save it to a file named \"OutputComparison.json\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f344a6f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f344a6f9",
        "outputId": "6614bebb-044d-44c1-f738-87da9e7e5d37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/ComparativeAnalysis.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 'sentence_reviews' will hold each sentence's analysis, including the original Brown tags, and both NLTK and spaCy's outputs.\n",
        "sentence_reviews = [\n",
        "    {\n",
        "        \"Sentence Index\": sentence_num,\n",
        "        \"Brown Original Tags\": adjusted_pos_tags[sentence_num - 14],\n",
        "        \"Output from NLTK\": nltk_annotated[sentence_num - 14],\n",
        "        \"Output from spaCy\": spacy_annotated[sentence_num - 14]\n",
        "    }\n",
        "    for sentence_num in range(14, 24)\n",
        "]\n",
        "\n",
        "# Writing the comparative analysis to a JSON file for easy review and sharing.\n",
        "comparison_json_path = \"/gdrive/My Drive/ComparativeAnalysis.json\"\n",
        "with open(comparison_json_path, \"w\") as file:\n",
        "    json.dump(sentence_reviews, file, indent=2)  # Using a two-space indent for compactness\n",
        "\n",
        "comparison_json_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "559bea00",
      "metadata": {
        "id": "559bea00"
      },
      "source": [
        "## Data Analysis\n",
        "\n",
        "The data analysis within Python environment could involve:\n",
        "\n",
        "- **Descriptive Statistics:** Compute statistics like mean, median, or mode to summarize the agreement rates or the frequency of specific POS tags.\n",
        "- **Visualization:** Create visualizations such as bar charts to compare the frequency of POS tags assigned by each framework or to visualize agreement rates.\n",
        "- **Clustering or Anomaly Detection:** Identify patterns or outliers in the tagging or lemmatization outputs, which could indicate systemic differences between the frameworks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ae7433",
      "metadata": {
        "id": "48ae7433"
      },
      "source": [
        "### Load the JSON Data and Generate the Spreadsheet\n",
        "\n",
        "In order to facilitate the analysis, we need to load the data from the JSON file into a format suitable for analysis, such as a Pandas DataFrame. Meanwhile, produce a spreadsheet based on the JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a3f4de",
      "metadata": {
        "id": "18a3f4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "9c9b9d82-6235-485d-f403-38d876f199a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sentence_Number Original_Words Original_POS  NLTK_Words  NLTK_Lemma  \\\n",
            "0                 14             ``           ``          ``          ``   \n",
            "1                 14           This           DT        This        This   \n",
            "2                 14             is          BEZ          is          is   \n",
            "3                 14            one           CD         one         one   \n",
            "4                 14             of           IN          of          of   \n",
            "..               ...            ...          ...         ...         ...   \n",
            "292               23            the           AT         the         the   \n",
            "293               23         prices          NNS      prices       price   \n",
            "294               23     reasonable           JJ  reasonable  reasonable   \n",
            "295               23             ''           ''          ``          ``   \n",
            "296               23              .            .           .           .   \n",
            "\n",
            "    NLTK_POS spaCy_Words spaCy_Lemma    spaCy_POS  \n",
            "0         ``         ` `         ` `  PUNCT PUNCT  \n",
            "1         DT        This        this         PRON  \n",
            "2        VBZ          is          be          AUX  \n",
            "3         CD         one         one          NUM  \n",
            "4         IN          of          of          ADP  \n",
            "..       ...         ...         ...          ...  \n",
            "292       DT         the         the          DET  \n",
            "293      NNS      prices       price         NOUN  \n",
            "294       JJ  reasonable  reasonable          ADJ  \n",
            "295       ``          ''          ''        PUNCT  \n",
            "296        .           .           .        PUNCT  \n",
            "\n",
            "[297 rows x 9 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'adjusted_processed_output.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Let's adjust the previous code to accommodate the new rule for handling spaCy tokenization of hyphenated words\n",
        "\n",
        "# Reload the JSON file, in case we need to process it again from scratch\n",
        "with open(comparison_json_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Prepare the data for the dataframe with the new rule for spaCy output\n",
        "prepared_data = []\n",
        "\n",
        "for sentence in data:\n",
        "    sentence_number = sentence['Sentence Index']\n",
        "    original_tags = sentence['Brown Original Tags']\n",
        "    nltk_output = sentence['Output from NLTK']\n",
        "    spacy_output = sentence['Output from spaCy']\n",
        "\n",
        "    # Adjust for spaCy tokenization of double backticks and hyphenated words\n",
        "    adjusted_spacy_output = []\n",
        "    i = 0\n",
        "    while i < len(spacy_output):\n",
        "        if i < len(spacy_output) - 1 and spacy_output[i] == [\"`\", \"`\", \"PUNCT\"] and spacy_output[i + 1] == [\"`\", \"`\", \"PUNCT\"]:\n",
        "            adjusted_spacy_output.append([\"` `\", \"` `\", \"PUNCT PUNCT\"])\n",
        "            i += 2  # Skip the next token as well\n",
        "        elif i < len(spacy_output) - 2 and spacy_output[i + 1][0] == \"-\":\n",
        "            # Combine the three parts of a hyphenated word into a single token\n",
        "            hyphenated_word = spacy_output[i][0] + \" - \" + spacy_output[i + 2][0]\n",
        "            hyphenated_lemma = spacy_output[i][1] + \" - \" + spacy_output[i + 2][1]\n",
        "            hyphenated_pos = spacy_output[i][2] + \" \" + spacy_output[i + 1][2] + \" \" + spacy_output[i + 2][2]\n",
        "            adjusted_spacy_output.append([hyphenated_word, hyphenated_lemma, hyphenated_pos])\n",
        "            i += 3  # Skip the next two tokens\n",
        "        else:\n",
        "            adjusted_spacy_output.append(spacy_output[i])\n",
        "            i += 1\n",
        "\n",
        "    # Ensure all lists are of the same length by padding shorter ones\n",
        "    max_length = max(len(original_tags), len(nltk_output), len(adjusted_spacy_output))\n",
        "    original_tags.extend([[\"\", \"\", \"\"]] * (max_length - len(original_tags)))\n",
        "    nltk_output.extend([[\"\", \"\", \"\"]] * (max_length - len(nltk_output)))\n",
        "    adjusted_spacy_output.extend([[\"\", \"\", \"\"]] * (max_length - len(adjusted_spacy_output)))\n",
        "\n",
        "    # Combine the data into a single list\n",
        "    for orig, nltk, spacy in zip(original_tags, nltk_output, adjusted_spacy_output):\n",
        "        prepared_data.append([\n",
        "            sentence_number,\n",
        "            orig[0], orig[2],\n",
        "            nltk[0], nltk[1], nltk[2],\n",
        "            spacy[0], spacy[1], spacy[2]\n",
        "        ])\n",
        "\n",
        "# Create the adjusted dataframe\n",
        "adjusted_df = pd.DataFrame(prepared_data, columns=[\n",
        "    'Sentence_No', 'Words_Brown', 'POS_Brown',\n",
        "    'Words_NLTK', 'Lemma_NLTK', 'POS_NLTK',\n",
        "    'Words_spaCy', 'Lemma_spaCy', 'POS_spaCy'\n",
        "])\n",
        "\n",
        "print(adjusted_df)\n",
        "\n",
        "# Save the adjusted dataframe to a new Excel file\n",
        "adjusted_output_file_path = '/gdrive/My Drive/adjusted_processed_output.xlsx'\n",
        "adjusted_df.to_excel(adjusted_output_file_path, index=False)\n",
        "\n",
        "adjusted_output_file_path"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}